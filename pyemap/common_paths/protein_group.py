import numpy as np
from io import StringIO
import os
import shutil
from ..process_data import process
from collections import OrderedDict
import networkx as nx
from networkx.algorithms import isomorphism
import time
import datetime
from ..data import char_to_res_name,res_name_to_char
import re
from Bio import SeqIO
from Bio.Seq import Seq
from Bio.Align.Applications import MuscleCommandline
from Bio.SeqRecord import SeqRecord
from Bio.SeqUtils import seq1
from Bio.PDB import Superimposer
from Bio import AlignIO
from numpy import linalg as LA
import string
import matplotlib.pyplot as plt

def compare_graph_strings(str1,str2):
    if not len(str1) == len(str2):
        return False
    for i in range(0,len(str1)):
        if not str1[i] == str2[i] and not str1[i]=="*" and not str2[i]=="*":
            return False
    return True

def subgraph_rmsd(sg1,sg2,emaps):
    emap1 = emaps[sg1.graph['pdb_id']]
    emap2 = emaps[sg2.graph['pdb_id']]
    atoms1 = []
    atoms2 = []
    for node in sg1.nodes:
        res = emap1.residues[node]
        for atm in res.get_atoms():
            if 'CA' in atm.id:
                atoms1.append(atm)
    for node in sg2.nodes:
        res = emap2.residues[node]
        for atm in res.get_atoms():
            if 'CA' in atm.id:
                atoms2.append(atm)
    si = Superimposer()
    si.set_atoms(atoms1, atoms2)
    return si.rms

def nodes_and_edges_from_string(graph_str,edge_thresholds):
    graph_str = graph_str.replace(" ","")
    graph_str = list(graph_str)
    node_list = []
    idx = 0
    while idx<len(graph_str):
        if graph_str[idx] == "(":
            node_label=""
            idx+=1
            while not graph_str[idx]==")":
                node_label+=str(graph_str[idx])
                idx+=1
            node_list.append(node_label)
            idx+=1
        else:
            node_list.append(str(graph_str[idx]))
            idx+=1
    l1 = []
    for i in range(0,len(edge_thresholds)):
        l1.append(i+2)
    from itertools import product
    edge_combs = list(product(l1, repeat=len(node_list)-1))
    unique_edge_combs = []
    for edge_comb in edge_combs:
        ec = list(edge_comb)
        if ec not in unique_edge_combs and ec[::-1] not in unique_edge_combs:
            unique_edge_combs.append(ec)
    return node_list,unique_edge_combs

def strip_res_number(u):
    for i in range(0, len(u)):
        if u[i].isdigit():
            return u[:i]

def node_match(node1, node2):
    return node1['num_label'] == node2['num_label']

def edge_match(edge1, edge2):
    return edge1['num_label'] == edge2['num_label']


class SubgraphPattern():
    '''
    Stores all information regarding a subgraph pattern identified by the gSpan algorithm.

    Attributes
    ----------
    id: str
        Unique identifier for subgraph pattern. 
    generic_subgraph: :class:`networkx.Graph`
        Graph representation of subgraph pattern found by gSpan algorithm
    support: list of str
        List of PDB IDs which contain this subgraph
    protein_subgraphs: dict of protein subgraph id (str): :class:`networkx.Graph`
        Dict which contains protein subgraphs which match this subgraph pattern. Each entry has a unique identifier and a
        :class:`networkx.Graph` derived from the graphs generated by the :class:`~pyemap.emap` class which match 
        the pattern of this subgraph pattern.
    support_number: int
        Number of PDBs this subgraph pattern was identified in 
    '''

    def __init__(self, G, graph_number, support):
        '''Initializes SubgraphPattern object.

        Parameters
        ----------
        G: :class:`networkx.Graph`
            Graph representation of subgraph pattern found by gSpan algorithm
        graph_number: int
            Unique numerical ID of subgraph pattern
        support: list of str
            List of PDB IDs which contain this subgraph
        '''
        self.generic_subgraph = G
        self.support = support
        self.protein_subgraphs = {}
        self.support_number = len(support)
        self.id = str(graph_number) + "_" + str(self._gen_node_rep()) + "_" + str(self.support_number)

    def general_report(self):
        ''' Generates general report which describes this subgraph pattern.
        '''
        full_str = ""
        full_str+= "ID:" + str(self.id) + "\n"
        full_str+= "Support:" + str(self.support_number) + "\n"
        full_str+= "Where:" + str(self.support) + "\n"
        full_str+= "Adjacency list:\n"
        G = self.generic_subgraph
        for node in G.nodes:
            full_str+= G.nodes[node]['label'] + str(node) + ":["
            for neighbor in G.neighbors(node):
                full_str+= G.nodes[neighbor]['label'] + str(neighbor) + "(" + str(G.edges[(node,neighbor)]['num_label']) + "), "
            full_str=full_str[:-2]
            full_str+="]\n"
        return full_str

    def full_report(self):
        full_str = self.general_report()
        full_str += str(len(self.protein_subgraphs)) + " subgraphs matching this pattern were found.\n"
        full_str += "Graphs are classified using " + self.clustering_option + " clustering.\n\n"
        for key in self.eigenvector_sorted:
            graphs = self.eigenvector_sorted[key]
            full_str+=  "Group " + str(key) + ": " + str(len(graphs))+ " members\n---------------\n"
            for graph in graphs:
                full_str+= self._report_for_graph(graph)+ "\n"
        return full_str

    def _report_for_graph(self,G):
        full_str = ""
        full_str+= str(G.graph['id']) + "\n"
        full_str+="Nodes\n"
        for node in G.nodes:
            full_str+=G.nodes[node]['label']
            full_str+= " Position in alignment:" + str(G.nodes[node]['aligned_resnum'])
            full_str+="\n"
        full_str+="Adjacency list:\n"
        for node in G.nodes:
            full_str+= G.nodes[node]['label'] + ":["
            for neighbor in G.neighbors(node):
                dist = '{0:.2f}'.format(G.edges[(node,neighbor)]['distance'])
                full_str+= G.nodes[neighbor]['label'] + "(" + str(dist) + "), "
            full_str=full_str[:-2]
            full_str+="]\n"
        return full_str

    def _gen_node_rep(self):
        node_rep = ""
        for node, node_data in self.generic_subgraph.nodes(data=True):
            node_rep = ''.join([node_rep, node_data['label']])
        return node_rep


    def visualize_subgraph_in_ngl(self,emap,G):
        ''' Gets visualization of subgraph in ngl viewer

        Parameters
        ----------
            emap: :class:`~pyemap.emap`
                :class:`~pyemap.emap` object containing the protein subgraph
            idx: int
                Index of protein subgraph to be visualized
        '''
        colors = {"F": "orange", "Y": "blue", "W": "red", "H": "green"}
        label_texts = []
        labeled_atoms = []
        color_list = []
        selection_strs = []
        for res in G.nodes:
            label_texts.append(res)
            try:
                if res not in emap.eta_moieties:
                    color_list.append(colors[res[0]])
                    labeled_atoms.append(".CA")
                else:
                    color_list.append("pink")
                    labeled_atoms.append(next(emap.residues[res].get_atoms()).name)
            except KeyError:
                color_list.append("pink")
                labeled_atoms.append(next(emap.residues[res].get_atoms()).name)
            selection_strs.append(emap.residues[res].ngl_string)
        return label_texts, labeled_atoms, color_list, selection_strs
    

    def clustering(self,all_graphs,emaps,clustering_option):
        self.eigenvector_sorted = {}
        dims = (len(all_graphs),len(all_graphs))
        if len(all_graphs)>1:
            if(clustering_option=="structural"):
                D,A = self._structural_clustering(all_graphs, emaps)
            else:
                D,A = self._sequence_clustering(all_graphs)
            self.clustering_option = clustering_option
            L = D - A
            eigv,eigvc=LA.eig(L)
            eigv = np.real(eigv)
            eigvc = np.real(eigvc)
            idx = eigv.argsort()
            eigv = eigv[idx]
            eigvc = eigvc[:,idx] 
            # second lowest eigenvector
            eigvc2 = eigvc[:,1]
            eigenvector_sorted = {}
            for i,val in enumerate(eigvc2):
                rounded_val = np.round(val,decimals=4)
                if rounded_val not in eigenvector_sorted:
                    eigenvector_sorted[rounded_val] = [all_graphs[i]]
                else:
                    graphs = eigenvector_sorted[rounded_val]
                    graphs.append(all_graphs[i])
                    eigenvector_sorted[rounded_val] =  graphs
            tuples = []
            for key,val in eigenvector_sorted.items():
                tuples.append((key,val))
            # largest groups first
            tuples.sort(key=lambda x: len(x[1]), reverse=True)
            for idx,tuple1 in enumerate(tuples):
                key,group = tuple1
                pdb_list = []
                for graph in group:
                    pdb_list.append(graph.graph['pdb_id'])
                    # ID is PDB_ID(group number)-index IN PDB e.g. 1U3D(1)-2 is the second subgraph from 1u3d which belongs to the first group
                    graph.graph['id'] = graph.graph['pdb_id']+"("+str(idx+1)+")-"+ str(pdb_list.count(graph.graph['pdb_id']))
                    graph.graph['group_val'] = key 
                    self.protein_subgraphs[graph.graph['id']] = graph
                self.eigenvector_sorted[idx+1] = group
        else:
            graph = all_graphs[0]
            graph.graph['id'] = graph.graph['pdb_id']+"("+str(1)+")-"+ str(1)
            graph.graph['group_val'] = 0.0 
            self.protein_subgraphs[graph.graph['id']] = graph
            self.eigenvector_sorted[1] = all_graphs        

    # clustering based on graph spectral method
    def _sequence_clustering(self,all_graphs):
        dims = (len(all_graphs),len(all_graphs))
        D = np.zeros(dims)
        A = np.zeros(dims)
        # adjacency matrix is distance between residues numbers in alignment
        # degree matrix is sum of all outgoing edges
        # J. Mol. Biol. (1999) 292, 441-464
        for i in range(0,len(all_graphs)):
            for j in range(i+1,len(all_graphs)):
                G1 = all_graphs[i]
                G2 = all_graphs[j]
                G2nodes = list(G2.nodes())
                distance = 0
                for k,node1 in enumerate(G1.nodes):
                    # only count for standard amino acid residues
                    if strip_res_number(node1) in char_to_res_name:
                        node2 = G2nodes[k]
                        distance+= np.absolute(G1.nodes[node1]['aligned_resnum'] - G2.nodes[node2]['aligned_resnum'])
                if distance<10:
                    A[i][j] = 1/(distance+1)
                    A[j][i] = 1/(distance+1)
                else:
                    A[i][j] = 0.001
                    A[j][i] = 0.001   
            D[i][i] = np.sum(A[i])
        return D,A

    def _structural_clustering(self,all_graphs,emaps):
        dims = (len(all_graphs),len(all_graphs))
        D = np.zeros(dims)
        A = np.zeros(dims)
        for i in range(0,len(all_graphs)):
            for j in range(i+1,len(all_graphs)):
                distance = subgraph_rmsd(all_graphs[i],all_graphs[j],emaps)
                if distance<1:
                    A[i][j] = 1/(distance+1)
                    A[j][i] = 1/(distance+1)
                else:
                    A[i][j] = 0.001
                    A[j][i] = 0.001   
            D[i][i] = np.sum(A[i])
        return D,A

class PDBGroup():
    '''
    Contains all information regarding the group of proteins being analyzed, and all of the of
    the subgraph patterns identified by the gSpan algorithm.

    Attributes
    ----------
    title: str
        Title of PDB group 
    emaps: dict of str: :class:`~pyemap.emap`
        Dict of PDBs being analyzed by PyeMap. The keys are PDB IDs, meaning that only one :class:`~pyemap.emap` object per PDB ID is allowed.
    temp_dir: str
        Path where temporary files are to be stored   
    subgraph_patterns: dict of str: :class:`~pyemap.common_paths.SubgraphPattern`
        Dict of subgraph patterns found by GSpan. Keys are the unique IDs of the :class:`~pyemap.common_paths.SubgraphPattern` objects.

    '''
    def __init__(self, title, temp_dir="."):
        ''' Initializes PDBGroup object
        
        Parameters
        ----------
        title: str
            Title of PDB group 
        temp_dir: str
            Path where temporary files are to be stored 
        '''
        self.title = title
        self.emaps = OrderedDict()
        self.temp_dir = temp_dir
        self.subgraph_patterns = {}
        self.res_to_num_label = {}
        self.num_label_to_res = {}
        self.edge_thresholds = []
        self.parameters = {}
        self.included_eta_moieties = {}
        self.included_chains = {}
        self.included_standard_residues = []
        self.sequences = {}
        self.aligned_sequences = {}

    def _clean_subgraphs(self):
        self.subgraph_patterns = {}
        self.res_to_num_label = {}
        self.num_label_to_res = {}
        self.edge_thresholds = []
        self.sep_buried_exposed = False

    def _reset_process(self):
        self.parameters = {}
        self.included_eta_moieties = {}
        self.included_chains = {}
        self.included_standard_residues = []
        self.sequences = {}
        self.aligned_sequences = {}
        self._clean_subgraphs()
        
    def _align_sequences(self,chains):
        records = []
        valid_ids = []
        for pdb_id,chain_list in chains.items():
            for chain in chain_list:
                valid_ids.append(pdb_id+":"+chain)
        for pdb_id,emap in self.emaps.items():
            seqIO = SeqIO.parse(emap.file_path, 'pdb-atom')
            for record in seqIO:
                if ":" not in record.id: 
                    record.id = pdb_id + ":" + record.id
                if record.id in valid_ids:
                    seqrec = SeqRecord(record.seq)
                    seqrec.id = record.id
                    seqrec.description = record.id
                    self.sequences[record.id] = record.seq
                    records.append(seqrec)
        SeqIO.write(records, os.path.join(self.temp_dir,"data.fasta"), "fasta")
        inp = os.path.join(self.temp_dir,"data.fasta")
        out =  os.path.join(self.temp_dir,"data_aligned.fasta")
        log = os.path.join(self.temp_dir , "log.txt")
        try:
            muscle_cline = MuscleCommandline(input=inp,
                                    out=out,
                                    log=log)
            muscle_cline()
        except:
            shutil.copyfile(inp,out)
        seqIO = SeqIO.parse(out,"fasta")
        for record in seqIO:
            self.aligned_sequences[record.id] = record.seq
        # now lets save the updated sequence numbers
        for pdb_id,emap in self.emaps.items():
            model = emap.structure[0]
            for chain in model:
                if pdb_id+":"+chain.id in self.aligned_sequences:
                    seq_map={}
                    aligned_seq = self.aligned_sequences[pdb_id+":"+chain.id]
                    original_seq = self.sequences[pdb_id+":"+chain.id]
                    original_idx = 0
                    aligned_idx = 0
                    num_gaps = 0
                    for res in aligned_seq:
                        if not res=="-":
                            residue_obj = list(chain.get_residues())[original_idx]
                            seq_map[residue_obj.id[1]] = aligned_idx
                            original_idx+=1
                        else:
                            num_gaps+=1
                        aligned_idx+=1
                    for res in chain:
                        if res.id[1] in seq_map:
                            res.aligned_residue_number = seq_map[res.id[1]]
                    for resname,res in emap.eta_moieties.items():
                        if res.get_full_id()[2] == chain.id:
                            res.aligned_residue_number = res.id[1] + num_gaps
       
    def process_emaps(self, chains=None, eta_moieties=None, include_residues=["TYR", "TRP"], **kwargs):
        ''' Processes :class:`~pyemap.emap` objects in order to generate protein graphs. 
        
        For a list of accepted kwargs, see the documentation for :func:`~pyemap.process_data.process`.

        Parameters
        -----------
        chains: dict of str: list of str, optional
            Chains to include for each PDB
        eta_moieties: dict of str: list of str, optional
            Dict containing list of ETA moieties(specified by their residue label) to include for each PDB
        
        Examples
        --------
        >>> my_pg = pyemap.common_paths.PDBGroup()
        >>> # Add pdbs 1u3d,1u3c,6PU0,4I6G,2J4D ...
        >>> eta_moieties = {'1u3d': ['FAD510(A)-2'], '1u3c': ['FAD510(A)-2'], '6PU0': ['FAD501(A)-2'], '4I6G': ['FAD900(A)-2'], '2J4D': ['FAD1498(A)-2']}
        >>> chains = {'1u3d': ['A'], '1u3c': ['A'], '6PU0': ['A'], '4I6G': ['A'], '2J4D': ['A']}
        >>> my_pg.process_emaps(chains=chains,eta_moieties=eta_moieties)

        '''
        # do nothing if processing params are the same
        if kwargs == self.parameters \
            and self.included_chains == chains \
            and self.included_eta_moieties==eta_moieties \
            and self.included_standard_residues == include_residues:
            return
        self._reset_process()
        if chains==None:
            chains = {}
            for pdb_id in self.emaps:
                chains[pdb_id] = [self.emaps[pdb_id].chains[0]]
        self._align_sequences(chains)
        for pdb_id in self.emaps:
            if not eta_moieties==None:
                cur_eta_moieties = eta_moieties[pdb_id]
            else:
                cur_eta_moieties = None
                print("Processing:" + str(pdb_id))
            process(self.emaps[pdb_id], chains=chains[pdb_id], eta_moieties=cur_eta_moieties, include_residues=include_residues, **kwargs)
        self.parameters = kwargs
        self.included_chains = chains
        self.included_eta_moieties = eta_moieties
        self.included_standard_residues = include_residues

    def report_header(self):
        full_str=""
        full_str+= "Generated:\n" + str(datetime.datetime.now()) + "\n"
        full_str+="Parameters:\n"
        if not self.parameters:
            full_str+="Custom.\n"
        else:
            full_str+=str(self.parameters)
            full_str+="\n"
        full_str+="Chains:\n"
        if not self.included_chains:
            full_str+="Custom.\n"
        else:
            full_str+=str(self.included_chains)
            full_str+="\n"
        full_str+="Included non protein moieties:\n"
        if not self.included_eta_moieties:
            full_str+="Custom.\n"
        else:
            full_str+=str(self.included_eta_moieties)
            full_str+="\n"
        full_str+="Edge thresholds:\n"+str(self.edge_thresholds)+"\n"
        full_str+="Node labels:\n"+str(self.res_to_num_label) + "\n"
        full_str+="Node categories:\n" + str(self.num_label_to_res) + "\n"
        return full_str
    
    def general_report(self,dest=None):
        ''' Generates general report of all subgraph patterns found in the analysis.

        Returns
        -------
        report: str
            General report of all subgraph patterns found in the analysis.
        '''
        full_str="Overview of all subgraphs:\n"
        full_str+=self.report_header()
        full_str+="\nSubgraphs found:\n\n"
        for fsg in self.subgraph_patterns:
            full_str+=self.subgraph_patterns[fsg].general_report()+"\n"
        if dest:
            fi = open(dest, "w")
            fi.write(full_str)
            fi.close()
        return full_str

    def subgraph_report(self,sg_id,dest=None):
        ''' Generates detailed report for a given subgraph pattern.

        Parameters
        -----------
        sg_id: str
            ID corresponding to a :class:`~pyemap.common_paths.SubgraphPattern` object 
        dest: str, optional
            Destination to write report to file

        Returns
        -------
        report: str
            Detailed report for a particular subgraph pattern.
        '''
        sg = self.subgraph_patterns[sg_id]
        full_str="Full report for subgraph:" + str(sg_id) + "\n"
        full_str+=self.report_header() + "\n"
        full_str+=sg.full_report()
        if dest:
            fi = open(dest, "w")
            fi.write(full_str)
            fi.close()
        return full_str

    def _set_edge_labels(self):
        all_edge_weights = []
        for id,emap in self.emaps.items():
            G = emap.init_graph
            for edge in G.edges:
                all_edge_weights.append(G.edges[edge]['weight'])
        mean = np.mean(all_edge_weights)
        std_dev = np.std(all_edge_weights)
        self.edge_thresholds = [mean,mean+std_dev]
        print(self.edge_thresholds)

    def _set_node_labels(self, node_labels, categories):
        self.res_to_num_label={}
        self.num_label_to_res={}
        if categories is not None and ("X" in node_labels or "X" in categories.values()):
            raise KeyError("X is reserved for unknown residue type. Do not use X as a key.")
        if not node_labels:
            num_label = 2
            for res in self.included_standard_residues:
                self.res_to_num_label[res_name_to_char[res]] = num_label
                self.num_label_to_res[num_label] = res_name_to_char[res]
                num_label+=1
            self.num_label_to_res[num_label] = "X"
            self.res_to_num_label["X"] = num_label
        else:
            self.num_label_to_res = categories
            self.res_to_num_label = node_labels
            # add back in categories for single subgraph search
            for key,val in categories.items():
                self.res_to_num_label[val] = key
            num_label = len(self.num_label_to_res) + 2
            self.num_label_to_res[num_label] = "X"
            self.res_to_num_label["X"] = num_label
        if self.sep_buried_exposed:
            num_label_to_res = self.num_label_to_res.copy()
            num_categories = len(self.num_label_to_res)
            for num_label,res_label in num_label_to_res.items():
                self.num_label_to_res[num_label+num_categories] = res_label+"_exp"
                self.res_to_num_label[res_label+"_exp"] = num_label+num_categories

    def _get_edge_label(self, G, edge):
        dist = G.edges[edge]['distance']
        label = 2
        for thresh in self.edge_thresholds:
            if dist < thresh:
                return label
            else:
                label += 1
        return label

    # _exp denotes surface exposed residue
    def _get_numerical_node_label(self, u, pdb_id):
        if strip_res_number(u) in char_to_res_name:
            res_name = strip_res_number(u)
            if self.sep_buried_exposed and self.emaps[pdb_id].init_graph.nodes[u]['shape'] == 'box':
                res_name+="_exp"
            result = self.res_to_num_label[res_name]
        elif (pdb_id+"_"+str(u)) in self.res_to_num_label:
            res_label = pdb_id+"_"+str(u)
            if self.sep_buried_exposed and self.emaps[pdb_id].init_graph.nodes[u]['shape'] == 'box':
                res_label+="_exp"
            result = self.res_to_num_label[res_label]
        else:
            if self.sep_buried_exposed and self.emaps[pdb_id].init_graph.nodes[u]['shape'] == 'box':
                result = self.res_to_num_label["X_exp"]
            else:
                result = self.res_to_num_label["X"]
        return result

    def add_emap(self, emap_obj):
        ''' Adds a parsed :class:`~pyemap.emap` object to the PDB group.

        Parameters
        ----------
            emap_obj: :class:`~pyemap.emap` object 
                Parsed PDB generated by :func:`~pyemap.parser.parse` or :func:`~pyemap.parser.fetch_and_parse`
        '''
        if emap_obj.pdb_id not in self.emaps:
            self.emaps[emap_obj.pdb_id] = emap_obj
            print("Added emap object with PDB ID: " + emap_obj.pdb_id)
        else:
            print("An emap object with PDB ID:" + str(emap_obj.pdb_id) + " is already in the data set. Skipping...")

    
    def generate_graph_database(self, node_labels=None, categories=None, sep_buried_exposed=False):
        ''' Generates graph database for analysis by GSpan using specified node labels, node categories, and edge thresholds.

        Parameters
        ----------
            node_labels: dict of str:int, optional
                Dict which maps residue labels to their numerical label for usage in the gSpan algorithm. Labels for non-standard
                residues should be preceded with the 4 character PDB ID followed by an underscore (e.g. 1u3d_FAD510(A)-2)
            categories: dict of int:str, optional
                Dict which maps numerical label to node category (which will appear in generic representation of subgraph pattern)
        
        Examples
        ---------
        >>> # labels for each type of residue included in analysis, including eta moieties grouped as a category
        >>> node_labels = {'1u3d_FAD510(A)-2': 2, '1u3c_FAD510(A)-2': 2, '6PU0_FAD501(A)-2': 2, 
                           '4I6G_FAD900(A)-2': 2, '2J4D_FAD1498(A)-2': 2, '1u3d_ANP511(A)': 3, 
                           'W': 4, 'Y': 5}
        >>> categories = {2: 'Fla', 3: 'Ade', 4: 'W', 5: 'Y'}
        >>> # edge length thresholds for categorizing edges
        >>> my_pg.generate_graph_database(node_labels=node_labels,categories=categories)

        '''
        self._clean_subgraphs()
        self.sep_buried_exposed = sep_buried_exposed
        self._set_node_labels(node_labels, categories)
        self._set_edge_labels()
        f = open(os.path.join(self.temp_dir, 'graphdatabase.txt'), "w")
        for i, key in enumerate(self.emaps):
            G = self.emaps[key].init_graph
            f.write("t # " + str(i) + "\n")
            for i, node in enumerate(G.nodes):
                f.write("v " + str(i) + " " + str(self._get_numerical_node_label(node,key)) + "\n")
            for i, edge in enumerate(G.edges):
                f.write("e " + str(list(G.nodes()).index(edge[0])) + " " + str(list(G.nodes()).index(edge[1])) + " " +
                        str(self._get_edge_label(G, edge)) + "\n")
        f.write("t # -1")
        f.close()

    def run_gspan(self, support, lower_bound=4,clustering_option="structural"):
        ''' Runs gSpan algorithm to mine for subgraph patterns, and then identifies each occurence of each subgraph pattern in each PDB which supports it.
        
        Parameters
        ----------
            support: int, optional
                Minimum support number of subgraphs in the search space 
            lower_bound: int, optional
                Minimum number of nodes for subgraphs in the search space
        '''
        if not clustering_option=="structural" and not clustering_option=="sequence":
            raise Exception("Either structural or sequence.")
        import sys
        old_stdout = sys.stdout
        f = open(os.path.join(self.temp_dir, 'gspan_results.out'), "w")
        sys.stdout = f
        from gspan_mining.config import parser
        from gspan_mining.main import main
        args_str = '-s ' + str(support) + ' -d False -l ' + str(lower_bound) + ' -p False -w True ' + str(
            os.path.join(self.temp_dir, 'graphdatabase.txt'))
        FLAGS, _ = parser.parse_known_args(args=args_str.split())
        gs = main(FLAGS)
        # give us our old standard output back
        sys.stdout = old_stdout
        f.close()
        self._generate_subgraph_patterns(clustering_option)

    def _generate_subgraph_patterns(self,clustering):
        buff = open(os.path.join(self.temp_dir, 'gspan_results.out'), "r")
        subgraphs = []
        lines = buff.readlines()
        line_idx = 0
        while line_idx < len(lines):
            line = lines[line_idx]
            if len(line.split()) == 3 and line.split()[0] == "t" and line.split()[1] == "#":
                graph_number = line.split()[2]
                line_idx += 1
                start_idx = line_idx - 1
                G = nx.Graph()
                line = lines[line_idx]
                while "---" not in line:
                    line = lines[line_idx]
                    if len(line.split()) > 1 and line.split()[0] == "v":
                        node_idx = int(line.split()[1])
                        node_label = int(line.split()[2])
                        G.add_node(node_idx)
                        G.nodes[node_idx]['label'] = self.num_label_to_res[node_label]
                        G.nodes[node_idx]['num_label'] = node_label
                    if len(line.split()) > 1 and line.split()[0] == "e":
                        idx1 = int(line.split()[1])
                        idx2 = int(line.split()[2])
                        edge_label = int(line.split()[3])
                        G.add_edge(idx1, idx2, label=edge_label)
                        G.edges[(idx1, idx2)]['num_label'] = edge_label
                    if "where" in line:
                        pdb_list_by_index = line[7:-2].strip('][').split(', ')
                        pdb_list_by_index = list(np.array(pdb_list_by_index, dtype=int))
                        pdb_list = list(self.emaps.keys())
                        support = []
                        for idx in pdb_list_by_index:
                            support.append(pdb_list[idx])
                        subgraphs.append(SubgraphPattern(G, graph_number, support))
                    line_idx += 1
            line_idx += 1
        buff.close()
        subgraphs.sort(key=lambda x: x.support_number, reverse=True)
        for sg in subgraphs:
            protein_subgraphs = []
            for pdb_id in sg.support:
                protein_subgraphs+=self._find_subgraph_in_pdb(sg.generic_subgraph, pdb_id)
            sg.clustering(protein_subgraphs,self.emaps,clustering)
            self.subgraph_patterns[sg.id] = sg


    def _generate_protein_subgraph(self, mapping, protein_graph, generic_subgraph):
        mapping = dict((v, k) for k, v in mapping.items())
        protein_subgraph = generic_subgraph.copy()
        protein_subgraph = nx.relabel_nodes(protein_subgraph, mapping)
        nodes = []
        for node in protein_subgraph.nodes():
            protein_subgraph.nodes[node]['shape'] = protein_graph.nodes[node]['shape']
            protein_subgraph.nodes[node]['label'] = str(node)
            protein_subgraph.nodes[node]['resnum'] = protein_graph.nodes[node]['resnum']
            protein_subgraph.nodes[node]['aligned_resnum'] = protein_graph.nodes[node]['aligned_resnum']
            protein_subgraph.graph['pdb_id'] = protein_graph.graph['pdb_id']
            nodes.append((node,protein_subgraph.nodes[node]['resnum']))
        for edge in protein_subgraph.edges():
            for key in protein_graph.edges[edge]:
                protein_subgraph.edges[edge][key] = protein_graph.edges[edge][key]
        return protein_subgraph

    def _find_subgraph_in_pdb(self, generic_subgraph, pdb_id):
        protein_graph = self.emaps[pdb_id].init_graph
        for node in protein_graph.nodes:
            protein_graph.nodes[node]['num_label'] = self._get_numerical_node_label(node,pdb_id)
        for edge in protein_graph.edges:
            protein_graph.edges[edge]['num_label'] = self._get_edge_label(protein_graph, edge)
        GM = isomorphism.GraphMatcher(protein_graph, generic_subgraph, node_match=node_match, edge_match=edge_match)
        subgraph_isos = GM.subgraph_monomorphisms_iter()
        sgs = []
        for mapping in subgraph_isos:
            sg = self._generate_protein_subgraph(mapping, protein_graph, generic_subgraph)
            sgs.append(sg)
        return sgs

    def find_subgraph(self,graph_specification,clustering_option="structural"):
        if not clustering_option=="structural" and not clustering_option=="sequence":
            raise Exception("Either structural or sequence.")
        node_list,edge_combs = nodes_and_edges_from_string(graph_specification,self.edge_thresholds)
        G = nx.Graph()
        for node_idx,node in enumerate(node_list):
            G.add_node(node_idx)
            G.nodes[node_idx]['label'] = node 
            G.nodes[node_idx]['num_label'] = self.res_to_num_label[node]
            if node_idx>0:
                G.add_edge(node_idx-1,node_idx)
        subgraph_patterns = []
        for edge_comb in edge_combs:
            for j,edge in enumerate(G.edges):
                G.edges[edge]['num_label'] = edge_comb[j]
                G.edges[edge]['label'] = edge_comb[j]
            protein_subgraphs = []
            support = []
            for pdb_id in self.emaps:
                protein_subgraphs_for_pdb=self._find_subgraph_in_pdb(G, pdb_id)
                if len(protein_subgraphs_for_pdb)>0:
                    protein_subgraphs+=protein_subgraphs_for_pdb
                    support.append(pdb_id)
            if len(protein_subgraphs)>0:
                fs = SubgraphPattern(G.copy(), len(subgraph_patterns), support)
                fs.clustering(protein_subgraphs,self.emaps,clustering_option)
                subgraph_patterns.append(fs)
        subgraph_patterns.sort(key=lambda x: x.support_number, reverse=True)
        for fs in subgraph_patterns:
            self.subgraph_patterns[fs.id] = fs
    
    def subgraph_rmsd(self,sg_id,key1,key2):
        my_sg = self.subgraph_patterns[sg_id]
        sg1 = my_sg.protein_subgraphs[key1]
        sg2 = my_sg.protein_subgraphs[key2]
        return subgraph_rmsd(sg1, sg2, self.emaps)

    def apply_filter(self,filter_str):
        matched_subgraphs = {}
        for key in self.subgraph_patterns.keys():
            idx1 = key.index("_")
            idx2 = key.index("_",idx1+1)
            graph_str = key[idx1+1:idx2]
            if compare_graph_strings(graph_str,filter_str):
                matched_subgraphs[key] = self.subgraph_patterns[key]
        return matched_subgraphs

